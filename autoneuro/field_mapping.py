# AUTOGENERATED! DO NOT EDIT! File to edit: 04_field_mapping.ipynb (unless otherwise specified).

__all__ = ['smrt_read', 'composite_function', 'fix_dates', 'fix_study_ids', 'FieldMapper']

# Cell

import pandas as pd

# Cell

def smrt_read(path, fix_id_col = None):
    if path.endswith('xls') or path.endswith('xlsx'):
        return pd.read_excel(path, na_values=['na', '-', 'nd'])
    elif path.endswith('csv'):
        return pd.read_csv(path, na_values=['na', '-', 'nd'])
    elif path.endswith('tsv') or path.endswith('tab'):
        return pd.read_csv(path, sep = '\t', na_values=['na', '-', 'nd'])
    raise ValueError(f'Could not load file {path}')

# Cell

from functools import reduce

# composite_function accepts N
# number of function as an
# argument and then compose them
def composite_function(*func):

    def compose(f, g):
        return lambda x : f(g(x))

    return reduce(compose, func, lambda x : x)



def fix_dates(df):

    df['date_of_visit'] = pd.to_datetime(df['date_of_visit'])
    return df

def fix_study_ids(df):

    ids = []
    for _id in df['study_id']:
        if type(_id) == str:
            _id = int(_id[1:])
        ids.append(_id)
    df['study_id'] = ids
    return df


# Cell

class FieldMapper(object):

    def __init__(self, mapping_df, post_convert = None):

        self.mapping_df = mapping_df
        if post_convert is None:
            self.post_convert = post_convert
        elif type(post_convert) == list:
            self.post_convert = composite_function(*post_convert)
        else:
            self.post_convert = post_convert

    @staticmethod
    def from_file(path, post_convert = None):

        if path.endswith('csv'):
            mapping_df = pd.read_csv(path)
        elif path.endswith('tsv'):
            mapping_df = pd.read_csv(path, sep = '\t')
        elif path.endswith('xlsx'):
            mapping_df = pd.read_excel(path)
        else:
            raise ValueError(f'Could not understand {path}')

        return FieldMapper(mapping_df, post_convert=post_convert)

    def convert(self, data, source_column, target_column, post_convert = True):

        assert source_column in self.mapping_df
        assert target_column in self.mapping_df

        source_fields = sorted(set(self.mapping_df[source_column].dropna()))
        target_fields = sorted(set(self.mapping_df[target_column].dropna()))

        id_df = self.mapping_df[[source_column, target_column]].dropna()
        id_dict = dict(row.values for _, row in id_df.iterrows())
        mapped_data = data.reindex(source_fields, axis=1).rename(columns = id_dict)
        mapped_data = mapped_data.loc[:, ~mapped_data.columns.duplicated()]

        #print(target_fields)
        mapped_data = mapped_data.reindex(target_fields, axis=1)

        if post_convert:
            if (type(post_convert) == bool) and self.post_convert is not None:
                mapped_data = self.post_convert(mapped_data)
            elif hasattr(post_convert, '__call__'):
                mapped_data = post_convert(mapped_data)

        return mapped_data


    def multi_merge(self, output_id, items, index_keys = ['study_id', 'patient_visit_number']):
        """Merge many files into the same ID system."""

        all_data = []
        all_inds = pd.MultiIndex.from_tuples([], names=index_keys)
        for source_id, dset in items:
            if type(dset) == str:
                dset = smrt_read(dset)
            all_data.append(self.convert(dset, source_id, output_id).groupby(index_keys).first())

            all_inds = all_inds.union(all_data[-1].index)

        final_data = all_data[0].reindex(all_inds, axis=0)
        for dset in all_data[1:]:
            final_data = final_data.combine_first(dset)

        return final_data


    def update_field_mapping(self, *calculators):

        new_rows = []
        for calc in calculators:
            for op in calc.operations:
                new_rows.append(op.to_field_mapping())

        self.mapping_df = pd.concat([self.mapping_df, pd.DataFrame(new_rows)],
                                    axis=0, ignore_index=True)
        self.mapping_df = self.mapping_df.groupby('internal_field', as_index = False).last()




