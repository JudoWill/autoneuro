{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# default_exp operators\n",
    "\n",
    "from nbdev.showdoc import show_doc\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numexpr as ne"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Operators\n",
    "\n",
    "In order to be able to capture the transformations required to normalize neuro data with different styles\n",
    "we'll need a collection of operations to manage them.\n",
    "In the abstract, these operations should manage grabbing the relevant data and then serving the result back in a standardized form."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "class AbstractOperation(object):\n",
    "\n",
    "    fields = []\n",
    "    result_fields = []\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "        op_classes = [EquationOp,\n",
    "                      AggregationOp,\n",
    "                      ClipOp,\n",
    "                      NormativeLookupOp,\n",
    "                      CategoricalOp,\n",
    "                      BinnedScalingOp,\n",
    "                      EquationFilterOp]\n",
    "\n",
    "        for op_class in op_classes:\n",
    "            op = op_class.from_config(config)\n",
    "            if op is not None:\n",
    "                return op\n",
    "        raise NotImplementedError(f'Did not understand type: {config[\"type\"]}')\n",
    "        #return None\n",
    "\n",
    "    def process_single(self, row):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def explain(self, row):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def to_series(self, row):\n",
    "\n",
    "        series = pd.Series(dict((field, row.get(field)) for field in self.fields))\n",
    "        return series\n",
    "\n",
    "    def __call__(self, row):\n",
    "\n",
    "        res = self.process_single(row)\n",
    "        yield self.result_fields[0], res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "abs_op = AbstractOperation()\n",
    "assert type(abs_op) == AbstractOperation\n",
    "\n",
    "abs_op.fields = ['t1', 't2']\n",
    "test_data = {'t1': 1, 't2': 2, 'other': 3}\n",
    "ser = abs_op.to_series(test_data)\n",
    "assert (ser['t1'] == 1) & (ser['t2'] == 2) & ('other' not in ser)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, we'll uss the BVMT test as the example.\n",
    "But we're going to back up a step. Since there are a bunch of different intermediate values, I want to calculate those using operations.\n",
    "\n",
    "Measured Values:\n",
    " - `trial1` - Trial 1 successes\n",
    " - `trial2` - Trial 2 successes\n",
    " - `trial3` - Trial 3 successes\n",
    " - `delay` - Delayed Successes\n",
    " - `hits` - Successful recognitions with distractors\n",
    " - `false_pos` - False-positive recognitions\n",
    "\n",
    "Our goal is to define all of the operations required to calculated intermediate values (ie immediate)\n",
    "as well as scaled values.\n",
    "\n",
    "There are three derived values to calculate:\n",
    "  - `immediate`: the sum of the three trials\n",
    "  - `regonition`: the number of hits - false-positive recognitions\n",
    "  - `retention`: ratio of delayed successes and largest of the trial 2 & trial 3 successes\n",
    "\n",
    "The first two can be solved with basic equations.\n",
    "The third will require an additional strategy effort.\n",
    "\n",
    "## Basic Equations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#export\n",
    "class EquationOp(AbstractOperation):\n",
    "    \"Manipulate values with 1numexpr1 equations.\"\n",
    "\n",
    "    def __init__(self, out_field, equation, fields):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        out_field : str\n",
    "        equation : str\n",
    "        fields : list[str]\n",
    "        \"\"\"\n",
    "\n",
    "        self.fields = fields\n",
    "        self.equation = equation\n",
    "        self.result_fields = [out_field]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "        \"\"\"\n",
    "\n",
    "        Expecting yaml of the format:\n",
    "          type: equation\n",
    "          equation: \"hits-false_pos\"\n",
    "          fields: ['hits', 'false_pos']\n",
    "          out_field: 'recognition'\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : dict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        EquationOp\n",
    "        \"\"\"\n",
    "        if config['type'] == 'equation':\n",
    "            return EquationOp(config['out_field'],\n",
    "                              config['equation'],\n",
    "                              config['fields'])\n",
    "        return None\n",
    "\n",
    "    def explain(self, row):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        row : dict,pd.Series\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "        \"\"\"\n",
    "\n",
    "        res = self.process_single(row)\n",
    "        return f'Used Equation: {self.equation} = {res} = {self.result_fields[0]}'\n",
    "\n",
    "    def process_single(self, row):\n",
    "        \"\"\" Apply the equation to the row\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        row : mapping\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        #print(data)\n",
    "        if data.notnull().all():\n",
    "            res = pd.eval(self.equation, local_dict=data.to_dict())\n",
    "        else:\n",
    "            res = np.nan\n",
    "        return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's imagine a individual to test.\n",
    "\n",
    "Measured Values:\n",
    " - `trial1` - 5\n",
    " - `trial2` - 6\n",
    " - `trial3` - 7\n",
    " - `delay` - 8\n",
    " - `hits` - 6\n",
    " - `false_pos` - 2\n",
    " - `copy` - 12\n",
    "\n",
    "Using the `EquationOp` let's calculate `immediate` and `recognition`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "DATA = {'trial1': 5, 'trial2': 6, 'trial3': 7,\n",
    "        'delay': 8, 'hits': 6, 'false_pos': 2,\n",
    "        'copy': 12}\n",
    "\n",
    "total_op = EquationOp('immediate',\n",
    "                      'trial1+trial2+trial3',\n",
    "                      ['trial1', 'trial2', 'trial3'])\n",
    "immed = total_op.process_single(DATA)\n",
    "assert immed == 18\n",
    "DATA['immediate'] = immed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also `explain` the result using the method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Equation: trial1+trial2+trial3 = 18 = immediate\n"
     ]
    }
   ],
   "source": [
    "print(total_op.explain(DATA))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While one might construct these operations in Python code, I actually expect most things to be saved as yaml.\n",
    "So, we need a way to represent this info in that format.\n",
    "This is also useful when constructing larger sets.\n",
    "\n",
    "Here's the yaml example for the recognition calculation.\n",
    "```\n",
    "type: equation\n",
    "equation: \"hits-false_pos\"\n",
    "fields: ['hits', 'false_pos']\n",
    "out_field: 'recognition'\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Equation: hits-false_pos = 4 = recognition\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "st = \"\"\"\n",
    "type: equation\n",
    "equation: \"hits-false_pos\"\n",
    "fields: ['hits', 'false_pos']\n",
    "out_field: 'recognition'\n",
    "\"\"\"\n",
    "\n",
    "ret_op = EquationOp.from_config(yaml.full_load(st))\n",
    "recog = ret_op.process_single(DATA)\n",
    "\n",
    "assert recog == 4\n",
    "print(ret_op.explain(DATA))\n",
    "DATA['recognition'] = recog\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregation Operations\n",
    "\n",
    "Due to limitations in numexpr, it cannot choose the largest of two numbers, as needed for retention.\n",
    "So, we use an `AggregationOp`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class AggregationOp(AbstractOperation):\n",
    "\n",
    "    def __init__(self, out_field, aggregation, fields):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        out_field : str\n",
    "        aggregation : str\n",
    "        fields : list[str]\n",
    "        \"\"\"\n",
    "\n",
    "        self.fields = fields\n",
    "        self.aggregation = aggregation\n",
    "        self.result_fields = [out_field]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "        \"\"\"\n",
    "        Load from config. Expects:\n",
    "            type: agg\n",
    "            method: 'max'\n",
    "            fields: ['trial2', 'trial3']\n",
    "            out_field: retention_denom\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : dict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        AggregationOp\n",
    "        \"\"\"\n",
    "        if config['type'] == 'agg':\n",
    "            return AggregationOp(config['out_field'],\n",
    "                                 config['method'],\n",
    "                                 config['fields'])\n",
    "        return None\n",
    "\n",
    "    def explain(self, row):\n",
    "        res = self.process_single(row)\n",
    "        return f'Aggregation: {self.aggregation} [{\", \".join(self.fields)}]  = {res}'\n",
    "\n",
    "    def process_single(self, row):\n",
    "        data = self.to_series(row)\n",
    "        return data.agg(self.aggregation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation: max [trial2, trial3]  = 7\n"
     ]
    }
   ],
   "source": [
    "ret_denom_op = AggregationOp('retention_denom', 'max', ['trial2', 'trial3'])\n",
    "re_denom = ret_denom_op.process_single(DATA)\n",
    "\n",
    "assert re_denom == 7\n",
    "print(ret_denom_op.explain(DATA))\n",
    "DATA['retention_denom'] = re_denom"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the denominator we can do another equation to calculate recognition."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Equation: delay/retention_denom = 1.1428571428571428 = retention\n"
     ]
    }
   ],
   "source": [
    "retent_op = EquationOp('retention', 'delay/retention_denom', ['delay', 'retention_denom'])\n",
    "retent = retent_op.process_single(DATA)\n",
    "\n",
    "assert retent == 8/7\n",
    "print(retent_op.explain(DATA))\n",
    "DATA['retention'] = retent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dang, the value was above 100%. And sometimes it may be negative.\n",
    "By convention we clip these to a [0,1] scale, which we'll need an operation for that.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#export\n",
    "class ClipOp(AbstractOperation):\n",
    "\n",
    "    def __init__(self, field, lower = 0, upper=1):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        field : str\n",
    "        lower : float\n",
    "        upper : float\n",
    "        \"\"\"\n",
    "\n",
    "        self.fields = [field]\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.result_fields = [field]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "        \"\"\"\n",
    "        Load from config. Expects:\n",
    "            type: clip\n",
    "            field: retention\n",
    "            lower: 0\n",
    "            upper: 1\n",
    "        Parameters\n",
    "        ----------\n",
    "        config\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ClipOp\n",
    "\n",
    "        \"\"\"\n",
    "        if config['type'] == 'clip':\n",
    "            return ClipOp(config['field'],\n",
    "                          lower = config['lower'],\n",
    "                          upper = config['upper'])\n",
    "        return None\n",
    "\n",
    "    def explain(self, row):\n",
    "        return f'Clipped {self.fields[0]} to [{self.lower}, {self.upper}]'\n",
    "\n",
    "    def process_single(self, row):\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        clipped = data.clip(lower=self.lower, upper=self.upper)\n",
    "        return clipped[self.result_fields[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipped retention to [0, 1]\n"
     ]
    }
   ],
   "source": [
    "ret_clip_op = ClipOp('retention', lower=0, upper=1)\n",
    "ret_clip = ret_clip_op.process_single(DATA)\n",
    "\n",
    "assert ret_clip == 1\n",
    "print(ret_clip_op.explain(DATA))\n",
    "DATA['retention'] = ret_clip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we've calculated all of the intermediate values.\n",
    "We'll need to use these values, along with demographic data, to lookup a \"healthy\" normal distribution.\n",
    "\n",
    "## Normative Lookups\n",
    "\n",
    "These lookup tables are composed of lookup tables that index a mean and std given a demographic filter.\n",
    "For example:\n",
    "\n",
    "A 32 year old should have an `immediate` memory of 26.9 with a std of 4.6.\n",
    "Our example has an `immediate` of 18, a deficit of 9, roughly 2 stds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class NormativeLookupOp(AbstractOperation):\n",
    "    \"\"\"Lookup table with normalized scores.\"\"\"\n",
    "\n",
    "    def __init__(self, lookup_table, filter_cols, measure_col, out_name):\n",
    "\n",
    "        self.lookup_table = lookup_table\n",
    "        self.filter_cols = filter_cols\n",
    "        self.fields = filter_cols + [measure_col]\n",
    "        self.result_fields = [out_name]\n",
    "        self.measure_col = measure_col\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "\n",
    "        if config['type'] == 'normative_lookup':\n",
    "\n",
    "            return NormativeLookupOp(config['table'],\n",
    "                                     config['filter_cols'],\n",
    "                                     config['measure_col'],\n",
    "                                     config['out_name'])\n",
    "        return None\n",
    "\n",
    "    def lookup_norm(self, row):\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        for filt in self.lookup_table:\n",
    "            if ne.evaluate(filt['filter'], local_dict=data):\n",
    "                return filt['filter'], filt['mean'], filt['std']\n",
    "\n",
    "        return None, None, None\n",
    "\n",
    "    def explain(self, row):\n",
    "\n",
    "        flt, mean, std = self.lookup_norm(row)\n",
    "        data = self.to_series(row)\n",
    "\n",
    "\n",
    "        if flt is None:\n",
    "            data = self.to_series(row)\n",
    "            return f'{self.result_fields[0]}: Could not find matching filter for {data[self.filter_cols]}'\n",
    "        else:\n",
    "            z = (data[self.measure_col] - mean)/std\n",
    "            return f'{self.result_fields[0]}: Matched {flt}, Expecting {mean} +- {std}, Observed: {data[self.measure_col]}, Z: {z}'\n",
    "\n",
    "    def process_single(self, row):\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        _, mean, std = self.lookup_norm(data)\n",
    "        if mean is None:\n",
    "            return np.nan\n",
    "        return (data[self.measure_col] - mean)/std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While it is possible to create these in Python, it's much easier to build using yaml definitions.\n",
    "\n",
    "```\n",
    "type: normative_lookup\n",
    "measure_col: immediate\n",
    "filter_cols: ['age']\n",
    "out_name: 'heaton_immediate'\n",
    "table:\n",
    "  - filter: (18 <= age) & (age <= 21)\n",
    "    mean: 28.74\n",
    "    std: 4.32\n",
    "  - filter: (20 <= age) & (age <= 23)\n",
    "    mean: 28.44\n",
    "    std: 4.38\n",
    "  ...\n",
    "\n",
    "```\n",
    "\n",
    "The filters are anything acceptable to `pd.eval`.\n",
    "The Heaton norms for the BVMT are currently in `data/norms/from_kate/heaton_bvmt.yaml`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched (30 <= age) & (age <= 33), Expecting 26.92 +- 4.64\n"
     ]
    }
   ],
   "source": [
    "DATA['age'] = 32\n",
    "bvmt_config = yaml.full_load(open('data/norms/from_kate/heaton_bvmt.yaml'))\n",
    "\n",
    "lookup_op = NormativeLookupOp.from_config(bvmt_config['operations'][0])\n",
    "lookup_score = lookup_op.process_single(DATA)\n",
    "\n",
    "assert lookup_score == -1.9224137931034488\n",
    "print(lookup_op.explain(DATA))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The collection of these operators can be combined into a `TestCalculator` which manages applying these operations sequentially.\n",
    "That is discussed elsewhere.\n",
    "\n",
    "These features are sufficient for any analysis that requires looking up normalizations based on demographic information.\n",
    "However, for regression based norms like the `Norman` set we need a further collection of operators.\n",
    "\n",
    "## Regression Based Norms\n",
    "\n",
    "When doing regression based normalization the first step is to `scale` the raw values based on a set of bins.\n",
    "This is done to help _normalize_ the raw values before entering the regression equation.\n",
    "\n",
    "For example. When scaling the `delay` column, the `norman` scheme uses:\n",
    "\n",
    "| Raw | Scaled |\n",
    "|-----|--------|\n",
    "| 12  | 14\n",
    "| 11  | 11\n",
    "| 10  | 9\n",
    "| 9   | 8\n",
    "| 8   | 7\n",
    "| 7   | 6\n",
    "| 5   | 5\n",
    "| 4   | 4\n",
    "| 3   | 3\n",
    "| 0   | 2\n",
    "\n",
    "The `BinnedScalingOp` can be used to deal with these conditions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class BinnedScalingOp(AbstractOperation):\n",
    "    def __init__(self, bins, measure_col, out_field = None):\n",
    "\n",
    "\n",
    "        self.fields = [measure_col]\n",
    "        if out_field is None:\n",
    "            self.result_fields = [measure_col+'_scaled']\n",
    "        else:\n",
    "            self.result_fields = [out_field]\n",
    "        self.bins = sorted(bins, key = lambda x: x['min'],\n",
    "                           reverse=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "        \"\"\"\n",
    "        Build from config, Expecting yaml like:\n",
    "          type: binned_scaling\n",
    "          measure_col: delay\n",
    "          bins:\n",
    "            - scaled: 14\n",
    "              min: 12\n",
    "            - scaled: 11\n",
    "              min: 11\n",
    "            - scaled: 9\n",
    "              min: 10\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        BinnedScalingOp\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if config['type'] == 'binned_scaling':\n",
    "            return BinnedScalingOp(config['bins'],\n",
    "                                   config['measure_col'])\n",
    "        return None\n",
    "\n",
    "    def lookup_bin(self, row):\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        val = data[self.fields[0]]\n",
    "        if val == val:\n",
    "            for bin in self.bins:\n",
    "                if val >= bin['min']:\n",
    "                    return bin['min'], bin['scaled']\n",
    "            return np.nan, np.nan\n",
    "        else:\n",
    "            return np.nan, np.nan\n",
    "\n",
    "    def explain(self, row):\n",
    "\n",
    "        edge, scaled = self.lookup_bin(row)\n",
    "\n",
    "        if edge != edge:\n",
    "            data = self.to_series(row)\n",
    "            return f'Could not find matching bin for {data[self.fields[0]]}'\n",
    "        else:\n",
    "            return f'{self.fields[0]} matched {edge}, scaled to {scaled}'\n",
    "\n",
    "    def process_single(self, row):\n",
    "        _, res = self.lookup_bin(row)\n",
    "        return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delay matched 8, scaled to 7\n"
     ]
    }
   ],
   "source": [
    "bins = [{'min': 12, 'scaled': 14},\n",
    "        {'min': 11, 'scaled': 11},\n",
    "        {'min': 10, 'scaled': 9},\n",
    "        {'min': 9, 'scaled':  8},\n",
    "        {'min': 8, 'scaled': 7},\n",
    "        {'min': 7, 'scaled': 6},\n",
    "        {'min': 5, 'scaled': 5},\n",
    "        {'min': 4, 'scaled': 4},\n",
    "        {'min': 3, 'scaled': 3},\n",
    "        {'min': 0, 'scaled': 2}]\n",
    "\n",
    "scale_op = BinnedScalingOp(bins, 'delay')\n",
    "delay_scaled = scale_op.process_single(DATA)\n",
    "\n",
    "assert delay_scaled == 7\n",
    "print(scale_op.explain(DATA))\n",
    "\n",
    "DATA['delay_scaled'] = delay_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the scaled value we need to handle the demographic variables.\n",
    "For the `norman` set Male gender is set to 1 with females as 0.\n",
    "The race also needs to be converted with white = 0 and AA = 1.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class CategoricalOp(AbstractOperation):\n",
    "\n",
    "    def __init__(self, measure_col, mapping, out_col):\n",
    "\n",
    "        self.result_fields = [out_col]\n",
    "        self.mapping = mapping\n",
    "        self.fields = [measure_col]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "        \"\"\"\n",
    "        Build from config. Expects yaml like:\n",
    "          type: categorical\n",
    "          in_field: gender\n",
    "          out_field: norman_gender\n",
    "          mapping:\n",
    "            male: 0\n",
    "            female: 1\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : dict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if config['type'] == 'categorical':\n",
    "            return CategoricalOp(config['in_field'],\n",
    "                                 config['mapping'],\n",
    "                                 config['out_field'])\n",
    "        return None\n",
    "\n",
    "    def lookup(self, row):\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        return self.mapping.get(data[self.fields[0]])\n",
    "\n",
    "    def process_single(self, row):\n",
    "\n",
    "        return self.lookup(row)\n",
    "\n",
    "    def explain(self, row):\n",
    "\n",
    "        res = self.lookup(row)\n",
    "        if res is not None:\n",
    "            return f'{self.fields[0]}:{row[self.fields[0]]} -> {self.result_fields[0]}:{res}'\n",
    "        else:\n",
    "            return f'Could not match {self.fields[0]}:{row[self.fields[0]]}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender:male -> norman_gender:0\n"
     ]
    }
   ],
   "source": [
    "cat_op = CategoricalOp('gender', {'male': 0, 'female': 1}, 'norman_gender')\n",
    "DATA['gender'] = 'male'\n",
    "\n",
    "norman_gender = cat_op.process_single(DATA)\n",
    "\n",
    "assert norman_gender == 0\n",
    "print(cat_op.explain(DATA))\n",
    "DATA['norman_gender'] = norman_gender"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now for the big finale, regression based norms.\n",
    "After scaling the relevant data and handling categorical variables we need to apply an equation.\n",
    "However, the equation changes depending on the individual's demographic variables.\n",
    "One for african americans, one for caucasians, and a different one for spanish speakers.\n",
    "The `EquationFilterOp` takes care of these intricacies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#export\n",
    "class EquationFilterOp(AbstractOperation):\n",
    "\n",
    "    def __init__(self, fields, regressions, out_field, result_type = 'zscale'):\n",
    "\n",
    "        self.regressions = regressions\n",
    "        self.fields = fields\n",
    "        self.result_fields = [out_field]\n",
    "        self.result_type = result_type\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "        if config['type'] == 'equation_filter':\n",
    "            return EquationFilterOp(config['fields'],\n",
    "                                    config['equations'],\n",
    "                                    config['out_field'],\n",
    "                                    result_type = config['result_type'])\n",
    "\n",
    "        return None\n",
    "\n",
    "    def search_filters(self, row):\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        check_func = lambda reg: pd.eval(reg['filter'], local_dict=data.to_dict())\n",
    "        return [reg for reg in self.regressions if check_func(reg)]\n",
    "\n",
    "    def scale_data(self, row):\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        hits = self.search_filters(row)\n",
    "        if hits: #Currently only implementing \"first\"\n",
    "            reg = hits[0]\n",
    "            val = pd.eval(reg['norm'], local_dict=data.to_dict())\n",
    "\n",
    "            if (self.result_type == 'standard_score') | (self.result_type == 'tscore'):\n",
    "                val = (val - 50)/10\n",
    "            elif (self.result_type  == 'zscore') | (self.result_type  == 'zscale'):\n",
    "                pass\n",
    "            elif self.result_type == 'other':\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f'Did not understand result_type: {self.result_type}')\n",
    "\n",
    "            return reg, val\n",
    "        return None, None\n",
    "\n",
    "\n",
    "    def explain(self, row):\n",
    "\n",
    "        data = self.to_series(row)\n",
    "        reg, val = self.scale_data(row)\n",
    "\n",
    "        if reg is None:\n",
    "            return 'Could not find a match for regression normalization.'\n",
    "        else:\n",
    "            return f'Matched {reg[\"filter\"]}, applied {reg[\"norm\"]} = {float(val)}'\n",
    "\n",
    "\n",
    "    def process_single(self, row):\n",
    "\n",
    "        _, val = self.scale_data(row)\n",
    "        return val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are best explained through their yaml imports.\n",
    "Examine the `data/norms/norman/norman_bvmt_regnorm.yaml` for a complete example.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}